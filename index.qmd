---
title: "Bayesian VARs Application: Inflation Rate Forecasts"
author: 
  - name: "Xiaoman Guo"
format:
  html:
    toc: true
    toc-location: left
---

> **Abstract.** This reseach project is motivated by the prevailing high inflation environment post COVID-19, aiming to investigate and forecast how inflation will evolve over time under the applicaion of the Bayesian Vector Autoregressions (VARs).

> **Keywords.** Bayesian VARs, inflation, cash rate, Minnesota prior, hyperparameter, stochastic volatility, heteroskedasticity, forecasting

## Objectives & Motivations

Following the pandemic, inflation in Australia has rapidly increased and peaked at 7.8 percent in 2022 Quarter 4, becoming the highest rate in over 30 years. This inflationary environment risks negative economic consequences such as reduced consumer purchasing power, as well as distortions in spending behaviour and investment decisions. This is a problem not only for central banks mandated to protect price stability and sustainable economic growth, but also for individuals who need to be informed about how prices (which directly affects our daily lives) will likely evolve in the future.

The objective of this research project is to forecast inflation using its dynamic interaction with 9 other economic variables, using Bayesian VARs models.

With this, we hope to address questions such as *"what would be the inflation rate in the next three years?"* and *"how soon will inflation in Australia return to the annual target 2 to 3 percent?"*.

## Data & Data Properties

```{r library}
#| echo: false
#| message: false
#| warning: false
library(readabs)
library(readrba)
library(openxlsx)
library(lubridate)
library(TSstudio)
library(xts)
library(tseries)
library(mvtnorm)
library(mvtnorm)
library(plot3D)
library(MASS)
library(HDInterval)
library(plotly)       
library(mgcv)
```

The 10 economic variables of interest are listed below,

-   $cpi_{t}$: the Consumer Price Index from the Australian Bureau of Statistics (ABS),

-   $cashr_{t}$: the Cash Rate of the Reserve Bank of Australia (RBA),

-   $gdp_{t}$: the Gross Domestic Product per capita seasonal adjusted from the ABS,

-   $lbr_{t}$: the unit labour cost seasonal adjusted from the ABS,

-   $unem_{t}$: the unemployment rate seasonal adjusted from the ABS,

-   $constru_{t}$: the Construction Work Done seasonal adjusted from the ABS,

-   $corpft_{t}$: the company profits before income tax seasonal adjusted from the ABS,

-   $export_{t}$: the International export in Goods and Services seasonal adjusted from the ABS,

-   $import_{t}$: the International import in Goods and Services seasonal adjusted from the ABS,

-   $arri_{t}$: the Overseas Arrivals from the ABS.

```{r variables}
#| echo: false
#| message: false
#| warning: false

# Inflation CPI 
# Index Numbers; Sep-1948 to Mar-2023
cpi_dwnld    = read_abs(series_id = "A2325846C")     
cpi_tmp      = xts::xts(cpi_dwnld$value, cpi_dwnld$date)
cpi_tmp      = log(cpi_tmp)   # log transformation of the index value 

# Cash rate target
# Percentage, monthly; Sep-1990 to Mar-2023
cashr_dwnld   = readrba::read_rba(series_id = "FIRMMCRT")   # Cash Rate Target
cashr_tmp     = xts::xts(cashr_dwnld$value, cashr_dwnld$date)
cashr_tmp     = apply.quarterly(cashr_tmp,mean)  # aggregate monthly to quarterly average
cashr_tmp     = xts(cashr_tmp, seq(as.Date("1990-09-01"), by = "quarter", length.out = length(cashr_tmp)))

# Gross Domestic Product per capita seasonal adjusted
# Index Numbers ; Sep-1973 to Dec-2022
gdp_dwnld    = read_abs(series_id = "A2304404C")     
gdp_tmp      = xts::xts(gdp_dwnld$value, gdp_dwnld$date)
gdp_tmp      = log(gdp_tmp)   # log transformation of the index value 

# Unit labour cost seasonal adjusted 
# Index Numbers; Sep-1985 to Dec-2022
lbr_dwnld    = read_abs(series_id = "A2433068T")     
lbr_tmp      = xts::xts(lbr_dwnld$value, lbr_dwnld$date)
lbr_tmp      = log(lbr_tmp)   # log transformation of the index value 

# Unemployment rate seasonal adjusted 
# Percentage; Feb-1978 to Apr-2023; MONTHLY 
unem_dwnld   = read_abs(series_id = "A84423050A")     
unem_tmp     = xts::xts(unem_dwnld$value, unem_dwnld$date)
unem_tmp     = apply.quarterly(unem_tmp,mean)
unem_tmp     = xts(unem_tmp, seq(as.Date("1978-03-01"), by = "quarter", length.out = length(unem_tmp)))

# Construction Work Done seasonal adjusted 
# Index Numbers; Sep-1976 to Dec-2022
# Chain Volume Measures: only vary with changes in the quantities of commodities produced or sold
constru_dwnld= read_abs(series_id = "A405136V")     
constru_tmp  = xts::xts(constru_dwnld$value, constru_dwnld$date)
constru_tmp  = log(constru_tmp)   # log transformation of the index value 

# Company profits before income tax seasonal adjusted
# Index Numbers; Sep-1985 to Dec-2022
corpft_dwnld  = read_abs(series_id = "A3530942R")     
corpft_tmp    = xts::xts(corpft_dwnld$value, corpft_dwnld$date)
corpft_tmp    = log(corpft_tmp)   # log transformation of the index value 

# International Trade in Goods and Services seasonal adjusted  
# Index Numbers; July-1971 to Mar-2023; MONTHLY
export_dwnld  = read_abs(series_id = "A2718603V")     
export_tmp    = abs(xts::xts(export_dwnld$value, export_dwnld$date))
export_tmp    = apply.quarterly(export_tmp,mean)
export_tmp    = log(export_tmp) 

import_dwnld  = read_abs(series_id = "A2718577A")     
import_tmp    = xts::xts(import_dwnld$value, import_dwnld$date)
import_tmp    = apply.quarterly(import_tmp,mean)
import_tmp    = log(import_tmp) 

# Overseas Arrivals 
# Index Numbers; Jan-1976 to Mar-2023; MONTHLY
arri_dwnld    = read_abs(series_id = "A85232561W")     
arri_tmp      = xts::xts(arri_dwnld$value, arri_dwnld$date)
arri_tmp      = apply.quarterly(arri_tmp,mean)
arri_tmp      = log(arri_tmp)

# All Variables
variables_all             = na.omit(merge(cpi_tmp, cashr_tmp, gdp_tmp, lbr_tmp, unem_tmp, constru_tmp, corpft_tmp,  export_tmp, import_tmp, arri_tmp ))
colnames(variables_all)   = c("cpi_tmp", "cashr_tmp", "gdp_tmp", "lbr_tmp", "unem_tmp", "constru_tmp","corpft_tmp", "export_tmp", "import_tmp", "arri_tmp")
```

*(Logarithm is performed on the index level data, and no data transformation is conducted on the rate data.)*

Quarterly time series plots are displayed below to visualize how the 10 proposed variables vary in the past 33 years starting from September 1990 to March 2023.

```{r all variables plot}
#| echo: false
#| message: false
#| warning: false

par(mfcol = c(3, 2), mar=c(2,2,2,2))
for (i in 1:6){ 
ts.plot(variables_all[,i], main =colnames(variables_all)[i], 
        ylab = "", xlab = "")
}

par(mfrow = c(2, 2), mar=c(2,2,2,2))
for (i in 7:10){ 
ts.plot(variables_all[,i], main =colnames(variables_all)[i], 
        ylab = "", xlab = "")
}
```

Most of the variables display an upward trend, with $cashr_{t}$ and $unem_{t}$ trending downwards. This strong trending pattern indicates that all the variables might integrate at 1, to know which, a formal Augmented Dickey-Fuller (ADF) test is conducted in the following section. $corpft_{t}$ and $arri_{t}$ exhibit the seasonality effect with a large drop at around Year 2021, which is a reflection of the start of the pandemic.

The autocorrelation (ACF) plot is presented below.

```{r all variables acf}
#| echo: false
#| message: false
#| warning: false

par(mfcol = c(3, 2), mar=c(2,2,2,2))
for (i in 1:6){
acf = acf(variables_all[,i], plot = FALSE)[1:20]
plot(acf, main = "")
title(main = paste(colnames(variables_all)[i]), line = 0.5)
}

par(mfrow = c(2, 2), mar=c(2,2,2,2))
for (i in 7:10){
acf = acf(variables_all[,i], plot = FALSE)[1:20]
plot(acf, main = "")
title(main = paste(colnames(variables_all)[i]), line = 0.5)
}
```

It is evident that the autocorrelation is very strong, reaching 1 at lag 1 for all variables.

The ADF test is conducted and presented below.

```{r all variable ADF}
#| echo: true
#| message: false
#| warning: false

## Augmented Dickey-Fuller test
adf.results = matrix(NA, ncol(variables_all), 1)
for (i in (1:ncol(variables_all))){
 adf = adf.test(variables_all[,i], k=4)
 adf.results[i] = round(adf$p.value,2)
}
colnames(adf.results) = c("p.value")
rownames(adf.results) = colnames(variables_all)
adf.results

# ADF test on I(1)
diff.all = na.omit(diff(variables_all))
for (i in (1:ncol(diff.all))){
 adf = adf.test(diff.all[,i], k=4)
 adf.results[i] = round(adf$p.value,2)
}
colnames(adf.results) = c("diff.p.value")
rownames(adf.results) = colnames(variables_all)
adf.results

# ADF test on I(2) - CPI
diff2.cpi = na.omit(diff(diff.all[,1]))
adf = adf.test(diff2.cpi, k=4)
adf.results = as.matrix(round(adf$p.value,2))
colnames(adf.results) = c("2 diff.p.value")
rownames(adf.results) = c("CPI")
adf.results
```

According to the ADF test results, all the variables are integrated at order 1, with $cpi_{t}$ integrating at 2 and $cashr_{t}$ being stationary.

To keep consistency, the first difference is taken on all variables. The whole dataset is now stationary with only $cpi_{t}$ being integrated at 1. We will address this in the Minnesota prior setup in the later section.

After the transformation, sub-dataset is presented as a reference. 

```{r variables transformation}
#| echo: false
#| message: false
#| warning: false

variables_all         = na.omit(diff(variables_all))
tail(variables_all[,1:2] )
```

Interpretations on the variables of interest,

-   $cpi_{t}$: at March 2023, there's a $1.37\%$ increase in the inflation in a quarter time. We can sum up the last 4 observations in the above table to get the annual inflation rate. which gives $6.79\%$.

-   $cashr_{t}$: at March 2023, there are 49 basis points increase in the cash rate target in a quarter time since December 2022.

The ADF test is conducted again in the transformed dataset for reference.

```{r variables transformation ADF}
#| echo: false
#| message: false
#| warning: false

## Augmented Dickey-Fuller test
adf.results = matrix(NA, ncol(variables_all), 1)
for (i in (1:ncol(variables_all))){
 adf = adf.test(variables_all[,i], k=4)
 adf.results[i] = round(adf$p.value,2)
}
colnames(adf.results) = c("p.value")
rownames(adf.results) = colnames(variables_all)
adf.results
```

## Model and Hypotheses

The basic model equation we will build upon throughout the research project is stated below with the error term specified in the matrix-variate normal distribution. It includes a $T \times 10$ dimension mean, a $10 \times 10$ dimension row specific covariance matrix and a $T$ dimension identity matrix referring to the column specified covariance.

-   $Y$ is a $T \times 10$ matrix representing the $10$ variables introduced in the model as explained previously and each variable extending out to $T$ periods.

-   $X$ is a $T \times K$ matrix with $T$ referring to the periods of time and $K = 1+10 \times P$ referring to $1$ intercept and $10$ variables, each of which has $p$ lags.

-   $A$ is a $K \times N$ matrix with $K$ corresponding to the total number of coefficients in each equation.

-   $E$ is a $T \times 10$ matrix referring to the error term in each of the equation.

```{=tex}
\begin{align}
Y &= XA + E \\
\end{align}
```
```{=tex}
\begin{align}
E |X  &\sim MN_{T \times 10 } (\textbf{0}_{T\times 10}, \Sigma , I_{T}) \\
\end{align}
```
## Modelling Framework

### Basic Model

The basic model is built on the natural-conjugate prior distribution, which is specified as a matrix normal inverse Wishart distribution. Minnesota prior expressing some stylised facts about the macroeconomic time series, in this case, $cpi_{t}$ being unit root non-stationary and the rest variables being stationary, is applied to form the specifications of the prior distribution.

The estimation procedures to draw from the posterior follows the steps below:

**Step 1**: The prior distribution is presented below. We will specify $\underline{A}$, $\underline{V}$, $\underline{S}$ and $\underline{v}$.

```{=tex}
\begin{align}
p(A,\Sigma) &= p(A|\Sigma)p(\Sigma)\\
A|\Sigma &\sim MN_{K\times N}(\underline{A}, \Sigma,\underline{V} ) \\ 
\Sigma &\sim IW_{N}(\underline{S}, \underline{v})
\end{align}
```
-   $\underline{A}$ is a $K \times N$ matrix being set to reflect the random walk with no drift process on the first lag of $cpi_{t}$, and 0 elsewhere.

```{=tex}
\begin{align}
\underline{A} = \left[ \underbrace{0_{N\times 1}}_{intercept} \quad 
\underbrace{ \begin{bmatrix}
1 & ... & 0 \\
\vdots &  \ddots & 0 \\
0 & ... & 0
\end{bmatrix} }_{N \times K-1}
\right]'
\end{align}
```
-   $\underline{V}$ represents the shrinking level of the specified $\underline{A}$. It's a $K$ vector diagonal matrix with the diagonal elements set to be the desired shrinking level, the larger the figure, the looser the shrinkage meaning larger variance is allowed; and off-diagonal being 0 as less information can be known about the covariances among the coefficients.

```{=tex}
\begin{align}
\underline{V} = diag\left[ \underbrace{k_{2}}_{intercept} \quad \underbrace{k_{1}(p^{-2}\otimes l^{'}_{N})}_{A_{1} \; to\;A_{p}}  \right]
\end{align}
```
-   $\underline{S}$ follows the econometrics convention to set as a $N$ vector diagonal matrix with the estimated $\widehat{\sigma}^{2}$ of each variable being the diagonal elements.

-   $\underline{v}$ is $N+1$.

**Step 2**: The posterior distribution is presented below with the implementation of the specification in Step 1. d

```{=tex}
\begin{align}
p(A,\Sigma | Y,X) &= p(A|Y,X,\Sigma)p(\Sigma|Y,X)\\
p(A|Y,X,\Sigma)&\sim MN_{K\times N}(\overline{A}, \Sigma,\overline{V} ) \\ 
p(\Sigma|Y,X)&\sim IW_{N}(\overline{S}, \overline{v})
\end{align}
```
```{=tex}
\begin{align}
\overline{V} &= (X'X + \underline{V}^{-1})^{-1} \\
\overline{A} &= \overline{V}(X'Y+\underline{V}^{-1}\underline{A}) \\
\overline{v} &= T + \underline{v} \\ 
\overline{S} &= \underline{S}+Y'Y+\underline{A'}\underline{V}^{-1}\underline{A}-\overline{A'}\overline{V}^{-1}\overline{A} \\
\end{align}
```
**Step 3**: Given $\overline{A}$, $\overline{V}$, $\overline{S}$ and $\overline{v}$ are now specified, we can firstly draw $\Sigma$ from $IW_{N}(\overline{S}, \overline{v})$, and take $\Sigma$ as known, then insert it in $MN_{K\times N}(\overline{A}, \Sigma,\overline{V} )$ to draw $A$.

The above steps are summarised in the below code to generate the sample draws from the joint posterior distribution.

```{r static data setup}
#| echo: false
#| message: false
#| warning: false
## Present data X, Y
y             = ts(variables_all[,1:ncol(variables_all)])
Y             = ts(y[5:nrow(y),], frequency=4)
X             = matrix(1,nrow(Y),1)
for (i in 1:frequency(Y)){
  X           = cbind(X,y[5:nrow(y)-i,])
}
 
## Pre-setup 
N             = ncol(Y)
p             = frequency(Y)
A.hat         = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat     = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

# Prior distribution specification - Minnesota prior 
kappa.1       = 10                                    # shrinkage for A1 to Ap
kappa.2       = 100                                   # shrinkage for constant 
A.prior       = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2,1]  = 1
V.prior       = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior       = diag(diag(Sigma.hat))
nu.prior      = N+1
```

```{r function based on basic model}
#| echo: true
#| message: false
#| warning: false

## Posterior sample draw function 
posterior.draws       = function (S, Y, X){
    # normal-inverse Wishard posterior parameters
    V.bar.inv         = t(X)%*%X + diag(1/diag(V.prior))
    V.bar             = solve(V.bar.inv)
    A.bar             = V.bar%*%(t(X)%*%Y + diag(1/diag(V.prior))%*%A.prior)
    nu.bar            = nrow(Y) + nu.prior
    S.bar             = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag(V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv         = solve(S.bar)
  
    # posterior draws 
    Sigma.posterior   = rWishart(S, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior   = apply(Sigma.posterior,3,solve)
    Sigma.posterior   = array(Sigma.posterior,c(N,N,S))
    A.posterior       = array(rnorm(prod(c(dim(A.bar),S))),c(dim(A.bar),S))
    L                 = t(chol(V.bar))
    for (s in 1:S){
      A.posterior[,,s]= A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])
    }
 
    output            = list(A.posterior=A.posterior, Sigma.posterior=Sigma.posterior)
    return(output)
}

## Applying function 
# A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
posterior.sample.draws = posterior.draws(S=50000, Y=Y, X=X)

# Presenting output
head(round(apply(posterior.sample.draws$A.posterior, 1:2, mean),6))         # posterior draw A
head(round(apply(posterior.sample.draws$Sigma.posterior, 1:2, mean),6))       # posterior draw sigma

par(mfrow=c(2,2), mar=c(4,4,2,2))
plot.ts(posterior.sample.draws$A.posterior[2,1,], xlab = "Simulation times S", ylab = "CPI", col = "darkblue")    
hist(posterior.sample.draws$A.posterior[2,1,], xlab = "CPI", col = "darkblue", main = '')
plot.ts(posterior.sample.draws$Sigma.posterior[1,1,], xlab = "Simulation times S", ylab = "CPI sigma", col = "skyblue") 
hist(posterior.sample.draws$Sigma.posterior[1,1,], xlab = "CPI sigma", col = "skyblue", main = '')
plot.ts(posterior.sample.draws$A.posterior[3,2,], xlab = "Simulation times S", ylab = "Cash Rate", col = "darkred") 
hist(posterior.sample.draws$A.posterior[3,2,], xlab = "Cash Rate", col = "darkred", main = '')
plot.ts(posterior.sample.draws$Sigma.posterior[2,2,], xlab = "Simulation times S", ylab = "Cash rate sigma", col = "pink")   
hist(posterior.sample.draws$Sigma.posterior[2,2,], xlab = "Cash rate sigma", col = "pink", main = '')          
```

The trace plots and histograms posterior draws on $A$ and $\Sigma$ are presented above. From the trace plots, it's evident that the inflation has a very strong perfect positive correlation with the prior period of itself, which aligns with the expectation of integration at 1 and the prior distribution setup. Cash rate shows some dependence to its prior period as well, with its coefficient moving between 0.5 to 1.

### Model Extension

The model extension applied in this research report is to build hierarchical model. The inverse gamma 2 distribution on the Minnesota shrinkage parameter kappa $k$ is introduced and specified below.

```{=tex}
\begin{align}
p(A,\Sigma, k |Y,X) &\propto L(Y,X|A,\Sigma)p(A,\Sigma, k)\\
&\propto L(Y,X|A,\Sigma)p(A |\Sigma, k)p(\Sigma)p(k)
\end{align}
```
where, each $p(A |\Sigma, k)$, $p(\Sigma)$, $p(k)$ is specified below.

```{=tex}
\begin{align}
p(A |\Sigma, k) &\sim MN_{K\times N}(\underline{A}, \Sigma, k\underline{V})\\
p(\Sigma) &\sim IW_{N}(\underline{S},\underline{v})\\
p(k) &\sim IG2(\underline{S_{k}}, \underline{v_{k}} ) \\ 
\end{align}
```
We multiply $L(Y,X|A,\Sigma)p(A|\Sigma, k)p(\Sigma)p(k)$ to get the kernel of the posterior distribution.

-   The kernel of the fully conditional posterior distribution of $A$ and $\Sigma$.

```{=tex}
\begin{align}
p(A,\Sigma |Y,X, k) &\propto L(Y,X|A,\Sigma)p(A |\Sigma, k)p(\Sigma) \\
&\propto \det(\Sigma)^{-\frac{T+N+K+\underline{v}+1}{2}} \\
&\exp\left\{ -\frac{1}{2} TR[\Sigma^{-1}[(A-\overline{A})'\overline{V}^{-1}(A-\overline{A})+\underline{S}+Y'Y+\underline{A}'(k\underline{V})^{-1}\underline{A}-\overline{A}'\overline{V}^{-1}\overline{A}]  ] \right\} \\
\end{align}
```
-   The kernel of the fully conditional posterior distribution of $k$.

```{=tex}
\begin{align}
p(k |Y,X,A,\Sigma ) &\propto L(Y,X|A,\Sigma)p(A,\Sigma, k)\\
&\propto L(Y,X|A,\Sigma)p(A |\Sigma, k)p(\Sigma)p(k) \\
&\propto p(A |\Sigma, k)p(k) 
\end{align}
```
```{=tex}
\begin{align}
p(k |Y,X,A,\Sigma ) &\propto \det(k\underline{V})^{-\frac{N}{2}}\exp\left\{-\frac{1}{2}TR[\Sigma^{-1}(A-\underline{A})'\underline{V}^{-1}(A-\underline{A})] \right\} k^{-\frac{\underline{v_{k}+2}}{2}}\exp\left\{ -\frac{1}{2}\frac{\underline{S_{k}}}{k} \right\} \\
& = k^{-\frac{kN+\underline{v_{k}+2}}{2}}\exp\left\{-\frac{1}{2}\frac{TR[\Sigma^{-1}(A-\underline{A})'\underline{V}^{-1}(A-\underline{A})]+\underline{S_{k}}}{k} \right\}
\end{align}
```
According to the above two kernels, the equation for each posterior parameter can be written as,

```{=tex}
\begin{align}
p(A |Y,X,\Sigma, k) &\sim MN_{K\times N}(\overline{A}, \Sigma, \overline{V})\\
p(\Sigma|Y,X,A,k) &\sim IW_{N}(\overline{S},\overline{v})\\
p(k |Y,X, A,\Sigma) &\sim IG2(\overline{S_{k}}, \overline{v_{k}} ) \\

\overline{V} &= (X'X + (k\underline{V})^{-1})^{-1}\\
\overline{A} &= \overline{V}(X'Y+(k\underline{V})^{-1}\underline{A}) \\
\overline{v} &= T+\underline{v}\\
\overline{S} &= \underline{S}+Y'Y+\underline{A}'(k\underline{V})^{-1}\underline{A}-\overline{A}'\overline{V}^{-1}\overline{A} \\
\overline{v_{k}} &= kN + \underline{v_{k}}\\
\overline{S_{k}} &= TR[\Sigma^{-1}(A-\underline{A})'\underline{V}^{-1}(A-\underline{A})]+\underline{S_{k}}\\

\end{align}
```
Since there is no analytical derivation of the joint posterior distribution $p(A,\Sigma, k |Y,X)$, the Gibbs sampler method will be applied to generate random draws from the full conditional posterior distribution of $A$, $\Sigma$ and $k$. The steps of the sample draws are explained as follows.

Initialize $k$ at $k^{(0)}$.

At each iteration $s$:

1.  Draw random matrices for $A^{(s)}$ and $\Sigma^{(s)}$ from $p(A,\Sigma|Y,X,k^{(s-1)})$.

2.  Draw a random number for $k^{(s)}$ from $p(k |Y,X,A^{(s)},\Sigma^{(s)})$.

Repeat steps 1 and 2 $S_{1} + S_{2}$ times.

Discard the first $S_{1}$ draws that allows the algorithm to converge to the stationary posterior distribution.

Output is the sample draws from the joint posterior distribution $\left\{ {A^{(s)}, \Sigma^{(s)}, k^{(s)}} \right\}^{S_{1}+S_{2}}_{s=S_{1}+1}$.

The above steps are summarised in the below code to generate the sample draws from the joint posterior distribution.

```{r function based on extended model}
#| echo: true
#| message: false
#| warning: false
# setup 
S1                = 5000                             # determine the burn-in draws
S2                = 45000                            # number of draws from the final simulation
total_S           = S1+S2
A.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))
Sigma.posterior   = array(NA, dim = c(N,N,S1+S2))
k.posterior       = matrix(NA, S1+S2, 1)

k.posterior[1]    = 10                               # set k0 

# Prior IG2 distribution: kappa
S.k.prior         = 3
nu.k.prior        = 5

## Posterior sample draw function for extended model  
posterior.draws.exten = function (total_S, Y, X){
for (s in 1:total_S){
    # normal-inverse Wishard posterior parameters
    V.bar.inv              = t(X)%*%X + diag(1/ diag( k.posterior[s]* V.prior))
    V.bar                  = solve(V.bar.inv)
    A.bar                  = V.bar%*%(t(X)%*%Y + diag(1/diag( k.posterior[s]* V.prior))%*%A.prior)
    nu.bar                 = nrow(Y) + nu.prior
    S.bar                  = S.prior + t(Y)%*%Y + t(A.prior)%*%diag(1/diag( k.posterior[s]* V.prior))%*%A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
    S.bar.inv              = solve(S.bar)
  
    # posterior draws for A and Sigma
    Sigma.posterior.IW     = rWishart(1, df=nu.bar, Sigma=S.bar.inv)
    Sigma.posterior.draw   = apply(Sigma.posterior.IW,3,solve)
    Sigma.posterior[,,s]   = Sigma.posterior.draw
    A.posterior[,,s]       = array(rnorm(prod(c(dim(A.bar),1))),c(dim(A.bar),1))
    L                      = t(chol(V.bar))
    A.posterior[,,s]       = A.bar + L%*%A.posterior[,,s]%*%chol(Sigma.posterior[,,s])
    
    # posterior draws for k
    if (s!=total_S){
    S.k.bar                = sum(diag( Sigma.posterior.IW[,,1] * t(A.posterior[,,s]-A.prior)%*%diag(1/diag(V.prior))%*%(A.posterior[,,s]-A.prior) )) + S.k.prior
    nu.k.bar               = (1+p*N)*N+ nu.k.prior 
    k.draw.tmp             = rchisq(1, df=nu.k.bar)
    k.draw                 = S.k.bar/k.draw.tmp
    k.posterior[s+1]       = k.draw
  }
}
    output                 = list (A.posterior.exten = A.posterior, Sigma.posterior.exten = Sigma.posterior, k.posterior.exten = k.posterior)
    return(output)
}
  
## Applying function 
posterior.ext = posterior.draws.exten(total_S = total_S, Y=Y, X=X)

# Presenting output
head(round(apply(posterior.ext$A.posterior.exten[,,(S1+1):total_S], 1:2, mean),6))
head(round(apply(posterior.ext$Sigma.posterior.exten[,,(S1+1):total_S], 1:2, mean),6))
round(mean(posterior.ext$k.posterior.exten[(S1+1):total_S]),6)

par(mfrow=c(2,2), mar=c(4,4,2,2))
plot.ts(posterior.ext$A.posterior.exten[2,1,(S1+1):total_S], xlab = "Simulation times S", ylab = "CPI.exten", col = "darkblue")   
hist(posterior.ext$A.posterior.exten[2,1,(S1+1):total_S], xlab = "CPI.exten", col = "darkblue", main = '')
plot.ts(posterior.ext$Sigma.posterior.exten[1,1,(S1+1):total_S], xlab = "Simulation times S", ylab = "CPI sigma.exten", col = "lightblue") 
hist(posterior.ext$Sigma.posterior.exten[1,1,(S1+1):total_S], xlab = "CPI sigma.exten", col = "lightblue", main = '')
plot.ts(posterior.ext$A.posterior.exten[3,2,(S1+1):total_S], xlab = "Simulation times S", ylab = "Cash Rate.exten", col = "darkred") 
hist(posterior.ext$A.posterior.exten[3,2,(S1+1):total_S], xlab = "Cash Rate.exten", col = "darkred", main = '')
plot.ts(posterior.ext$Sigma.posterior.exten[2,2,(S1+1):total_S], xlab = "Simulation times S", ylab = "Cash rate sigma.exten", col = "pink")   
hist(posterior.ext$Sigma.posterior.exten[2,2,(S1+1):total_S], xlab = "Cash rate sigma.exten", col = "pink", main = '')
par(mfrow=c(1,2), mar=c(4,4,2,2))
plot.ts(posterior.ext$k.posterior.exten[(S1+1):total_S], xlab = "Simulation times S", ylab = "kappa", col = "darkgreen")         
hist(posterior.ext$k.posterior.exten[(S1+1):total_S], xlab = "kappa", col = "darkgreen", main = '')
```

Compared to the basic model, by adding the kappa $k$ into the variance specification of the prior mean $A$, it introduces more variability of $A$. Instead of being a fixed shrinkage level, the variance of $A$ is non-constant. This change gives evident results on the inflation, the coefficient of which now has a broader range from 0.8 to 1, rather than 0.95 to 1 as in the basic model. The results on the cash rate are not obvious. This may be due to the cash rate being a stationary series.

The kappa $k$ mainly concentrates between 2 to 6, with some large outlines throughout the simulation.

### Heteroskedasticity Model

The model specification is as below.

```{=tex}
\begin{align}
Y &= XA + E \\
\end{align}
```
```{=tex}
\begin{align}
E |X  &\sim MN_{T \times 10 } (\textbf{0}_{T\times 10}, \Sigma , diag(\sigma_{T}^{2})) \\
\end{align}
```
Building upon the extended model, the posterior equations can now be written as,

```{=tex}
\begin{align}
\overline{V} &= (X'diag(\sigma_{T}^{2})^{-1}X + (k\underline{V})^{-1})^{-1}\\
\overline{A} &= \overline{V}(X'diag(\sigma_{T}^{2})^{-1}Y+(k\underline{V})^{-1}\underline{A}) \\
\overline{v} &= T+\underline{v}\\
\overline{S} &= \underline{S}+Y'diag(\sigma_{T}^{2})^{-1}Y+\underline{A}'(k\underline{V})^{-1}\underline{A}-\overline{A}'\overline{V}^{-1}\overline{A} \\
\overline{v_{k}} &= KN + \underline{v_{k}}\\
\overline{S_{k}} &= TR[\Sigma^{-1}(A-\underline{A})'\underline{V}^{-1}(A-\underline{A})]+\underline{S_{k}}\\
\end{align}
```

```{r heteroskedasticity}
#| echo: false
#| message: false
#| warning: false

# Setup heteroskedasticity
S1            = 5000                              # determine the burn-in draws
S2            = 45000                             # number of draws from the final simulation
total_S       = S1+S2

S.k.prior     = 3                                 # Prior IG2 distribution: kappa; set up based on the expectation and variance of IG2 distribution
nu.k.prior    = 5

T             = dim(Y)[1]
N             = dim(Y)[2]
K             = dim(X)[2]

H             = diag(T)
sdiag(H,-1)   =  -1
HH            = 2*diag(T)
sdiag(HH,-1)  =  -1
sdiag(HH,1)   =  -1

priors        = list(
  A.prior     = A.prior,
  V.prior     = V.prior,
  S.prior     = S.prior,
  nu.prior    = nu.prior,
  HH          = HH,
  h0.m        = 0,
  h0.v        = 1,
  sigmav.s    = 1,
  sigmav.nu   = 1
)

# Posterior sample draw function for heteroskedasticity on extended model  
posterior.draw.heter = function (total_S, Y, X, priors){

  posteriors    = list(                        
    H           = matrix(NA,T,total_S),
    sigma2      = matrix(NA,T,total_S),
    s           = matrix(NA,T,total_S),
    h0          = rep(NA,total_S),
    sigma.v2    = rep(NA,total_S),
    A           = array(NA, c(K,N,total_S)),
    Sigma       = array(NA, c(N,N,total_S)),
    kappa       = rep(NA, total_S)
  )
  
  aux = list(
    Y        = Y,
    X        = X,
    H        = matrix(1,T,1),
    h0       = 0,
    sigma.v2 = 1,
    s        = matrix(1,T,1),
    A        = matrix(0, K, N),
    Sigma    = matrix(0, N, N),             
    sigma2   = matrix(1,T,1),
    kappa    = 10
  )
  
  for (s in 1:total_S){
      # normal-inverse Wishard posterior parameters
      V.bar.inv              = t(aux$X)%*%diag(1/as.vector(aux$sigma2))%*%aux$X + diag(1/ diag( aux$kappa* priors$V.prior))
      V.bar                  = solve(V.bar.inv)
      A.bar                  = V.bar%*%(t(aux$X)%*%diag(1/as.vector(aux$sigma2))%*%aux$Y + diag(1/diag( aux$kappa* priors$V.prior))%*%priors$A.prior)
      nu.bar                 = T + priors$nu.prior
      S.bar                  = priors$S.prior + t(aux$Y)%*%diag(1/as.vector(aux$sigma2))%*%aux$Y + t(priors$A.prior)%*%diag(1/diag(aux$kappa* priors$V.prior))%*%priors$A.prior - t(A.bar)%*%V.bar.inv%*%A.bar
      S.bar.inv              = solve(S.bar)
    
      # posterior draws for A and Sigma
      Sigma.posterior.IW     = rWishart(1, df=nu.bar, Sigma=S.bar.inv)
      Sigma.posterior.draw   = apply(Sigma.posterior.IW, 3 ,solve)
      aux$Sigma              = array(Sigma.posterior.draw,c(N,N,1))
      A.norm                 = array(rnorm(prod(c(K,N,1))),c(K,N,1))
      L                      = t(chol(V.bar))
      aux$A                  = A.bar + L%*%A.norm[,,1]%*%chol(aux$Sigma[,,1])
    
      # posterior draws for k
      S.k.bar                = sum(diag( solve( aux$Sigma[,,1] ) * t(aux$A-priors$A.prior)%*%diag(1/diag(priors$V.prior))%*%(aux$A-priors$A.prior) )) + S.k.prior
      nu.k.bar               = K*N+ nu.k.prior 
      k.draw.tmp             = rchisq(1, df=nu.k.bar)
      k.draw                 = S.k.bar/k.draw.tmp
      aux$kappa              = k.draw
 
      # posterior draw for sigma2   
      N             = dim(aux$Y)[2]
      alpha.st      = c(1.92677,1.34744,0.73504,0.02266,0-0.85173,-1.97278,-3.46788,-5.55246,-8.68384,-14.65000)
      sigma.st      = c(0.11265,0.17788,0.26768,0.40611,0.62699,0.98583,1.57469,2.54498,4.16591,7.33342)
      pi.st         = c(0.00609,0.04775,0.13057,0.20674,0.22715,0.18842,0.12047,0.05591,0.01575,0.00115)
      
      Lambda        = solve(chol(aux$Sigma[,,1]))
      Z             = rowSums( ( aux$Y - aux$X %*% aux$A ) %*% Lambda ) / sqrt(N)
      Y.tilde       = as.vector(log((Z + 0.0000001)^2))
      Ytilde.alpha  = as.matrix(Y.tilde - alpha.st[as.vector(aux$s)])
        
      # sampling initial condition
      V.h0.bar      = 1/((1 / priors$h0.v) + (1 / aux$sigma.v2))
      m.h0.bar      = V.h0.bar*((priors$h0.m / priors$h0.v) + (aux$H[1] / aux$sigma.v2))
      h0.draw       = rnorm(1, mean = m.h0.bar, sd = sqrt(V.h0.bar))
      aux$h0        = h0.draw
      
      # sampling sigma.v2
      sigma.v2.s    = priors$sigmav.s + sum(c(aux$H[1] - aux$h0, diff(aux$H))^2)
      sigma.v2.draw = sigma.v2.s / rchisq(1, priors$sigmav.nu + T)
      aux$sigma.v2  = sigma.v2.draw
      
      # sampling auxiliary states
      Pr.tmp        = simplify2array(lapply(1:10,function(x){
        dnorm(Y.tilde, mean = as.vector(aux$H + alpha.st[x]), sd = sqrt(sigma.st[x]), log = TRUE) + log(pi.st[x])
      }))
      Pr            = t(apply(Pr.tmp, 1, function(x){exp(x - max(x)) / sum(exp(x - max(x)))}))
      s.cum         = t(apply(Pr, 1, cumsum))
      r             = matrix(rep(runif(T), 10), ncol = 10)
      ss            = apply(s.cum < r, 1, sum) + 1
      aux$s         = as.matrix(ss)
      
      # sampling log-volatilities using functions for tridiagonal precision matrix
      Sigma.s.inv   = diag(1 / sigma.st[as.vector(aux$s)])
      D.inv         = Sigma.s.inv + (1 / aux$sigma.v2) * priors$HH
      b             = as.matrix(Ytilde.alpha / sigma.st[as.vector(aux$s)] + (aux$h0/aux$sigma.v2)*diag(T)[,1])
      lead.diag     = diag(D.inv)
      sub.diag      = mgcv::sdiag(D.inv, -1)
      D.chol        = mgcv::trichol(ld = lead.diag, sd = sub.diag)
      D.L           = diag(D.chol$ld)
      mgcv::sdiag(D.L,-1) = D.chol$sd
      x             = as.matrix(rnorm(T))
      a             = forwardsolve(D.L, b)
      draw          = backsolve(t(D.L), a + x)
      aux$H         = as.matrix(draw)
      aux$sigma2    = as.matrix(exp(draw))
        
      # output list
      posteriors$H[,s]             = aux$H
      posteriors$sigma2[,s]        = aux$sigma2
      posteriors$s[,s]             = aux$s
      posteriors$h0[s]             = aux$h0
      posteriors$sigma.v2[s]       = aux$sigma.v2
      posteriors$A[,,s]            = aux$A
      posteriors$Sigma[,,s]        = aux$Sigma
      posteriors$kappa[s]          = aux$kappa
  }
        
  return(posteriors)
}
```

```{r heteroskedasticity 1}
#| echo: true
#| message: false
#| warning: false
# Applying function 
posterior.heter = posterior.draw.heter(total_S = total_S, Y = Y, X = X, priors = priors)

# Presenting output
head(round(apply(posterior.heter$A[,,(S1+1):total_S], 1:2, mean),6))
head(round(apply(posterior.heter$Sigma[,,(S1+1):total_S], 1:2, mean),6))
round(mean(posterior.heter$kappa[(S1+1):total_S]), 6)
round(apply(posterior.heter$sigma2[,(S1+1):total_S], 1, mean),6)

par(mfrow=c(2,2), mar=c(4,4,2,2))
plot.ts(posterior.heter$A[2,1,(S1+1):total_S], xlab = "Simulation times S", ylab = "CPI.heter", col = "darkblue") 
hist(posterior.ext$A.posterior.exten[2,1,(S1+1):total_S], xlab = "CPI.heter", col = "darkblue", main = '')
plot.ts(posterior.heter$Sigma[1,1,(S1+1):total_S], xlab = "Simulation times S", ylab = "CPI sigma.heter", col = "lightblue") 
hist(posterior.heter$Sigma[1,1,(S1+1):total_S], xlab = "CPI sigma.heter", col = "lightblue", main = '')
plot.ts(posterior.heter$A[3,2,(S1+1):total_S], xlab = "Simulation times S", ylab = "Cash Rate.heter", col = "darkred") 
hist(posterior.heter$A[3,2,(S1+1):total_S], xlab = "Cash Rate.heter", col = "darkred", main = '')
plot.ts(posterior.heter$Sigma[2,2,(S1+1):total_S], xlab = "Simulation times S", ylab = "Cash rate sigma.heter", col = "pink")   
hist(posterior.heter$Sigma[2,2,(S1+1):total_S], xlab = "Cash rate sigma.heter", col = "pink", main = '')
plot.ts(posterior.heter$kappa[(S1+1):total_S], xlab = "Simulation times S", ylab = "kappa", col = "darkgreen") 
hist(posterior.heter$kappa[(S1+1):total_S], xlab = "kappa.heter", col = "darkgreen", main = '')
plot.ts(apply(posterior.heter$sigma2[,(S1+1):total_S], 1, mean), ylab = "sigma2.heter")
```

After introducing the Stochastic Volatility conditional heteroskedasticity in the model, it increases the variability of all parameters in general, however the major characteristics still preserve.

-   The coefficient of the inflation still concentrates between 0.8 to 1, however many small outlines from 0.2 to 0.5 are picked up in the simulation. The trace plot of the variance of the inflation indicates more outliers than those we can find in the basic and extended model; however it's less dispersed, proved by the narrower histogram.

-   Similar findings can be seen in the cash rate and kappa. There are more outliers, however, overall less dispersed as per histogram.

-   A worth noting plot is the heteroskedasticity variance $\sigma_{T}^{2}$. It's clear that the variance is not constant. It has some high variance at time 0, 40, 70 and 110, corresponding to year 1990, 2000, 2008 and 2020. Not surprisingly, there was recession, or GFC or like most recently the COVID-19 happening, which drives the high volatility in the economy and the market. This plot is within expectation and worth adding into the model for capturing the time-varying variance.

### Model Proof

Artificial data is generated to contain 1,000 observations simulated from a bi-variate Gaussian random walk process with the covariance matrix equal to the identity matrix of order 2. By running the below codes, it can prove that both the basic and the extended models can replicate the true parameters of the data-generating process.

Since the models are reviewed in the past work, the below codes are display-only.

```{r test on basic model}
#| echo: true
#| message: false
#| warning: false
#| eval: false
m1 = cumsum(rnorm(1000, 0, sd=1))
m2 = cumsum(rnorm(1000, 0, sd=1))
m= cbind(m1,m2)

## Define data X, Y 
Y = ts(m[2:nrow(m),], frequency=1)
X = matrix(1,nrow(Y),1)
X = cbind(X,m[2:nrow(m)-1,])

## Test on basic model
N           = ncol(Y)
p           = frequency(Y)
A.hat       = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat   = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

# Prior distribution specification - Minnesota prior 
kappa.1     = 1                                   # shrinkage for A1 to Ap
kappa.2     = 10                                  # shrinkage for constant 
A.prior     = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2:(N + 1),] = diag(N)
V.prior     = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior     = diag(diag(Sigma.hat))
nu.prior    = N+1

# Applying function 
posterior.sample.draws = posterior.draws(S=100000, Y=Y, X=X)
round(apply(posterior.sample.draws$A.posterior, 1:2, mean),6)
round(apply(posterior.sample.draws$Sigma.posterior, 1:2, mean),6)
```

```{r test on extended model}
#| echo: true
#| message: false
#| warning: false
#| eval: false
# setup 
kappa.1     = 1                                # shrinkage for A1 to Ap
kappa.2     = 10                               # shrinkage for constant 
S1          = 100                              # determine the burn-in draws
S2          = 1000                             # number of draws from the final simulation
total_S     = S1+S2
A.posterior       = array(NA, dim = c((1+N*p),N,S1+S2))
Sigma.posterior   = array(NA, dim = c(N,N,S1+S2))
k.posterior       = matrix(NA, S1+S2, 1)
k.posterior[1]    = 10                         # set k0 

# Prior IG2 distribution: kappa
S.k.prior   = 2
nu.k.prior  = 4

# Applying function 
posterior.ext = posterior.draws.exten(total_S = total_S, Y=Y, X=X)
round(apply(posterior.ext$A.posterior.exten[,,(S1+1):S2], 1:2, mean),6)
round(apply(posterior.ext$Sigma.posterior.exten[,,(S1+1):S2], 1:2, mean),6)
```

## Forecasting

The aim of the forecasting is to predict how the variable of interest $cpi_{t}$ and $cashr_{t}$ are going to evolve in the next three years, that is $h=12$ steps ahead.

The forecasts are built on the three models discussed in this work, namely the basic model, the extended model and the heteroskedasticity model.

### Forecasting on basic model

```{r forecasting static data}
#| echo: false
#| message: false
#| warning: false
## Present data X, Y
y             = ts(variables_all[,1:ncol(variables_all)])
Y             = ts(y[5:nrow(y),], frequency=4)
X             = matrix(1,nrow(Y),1)
for (i in 1:frequency(Y)){
  X           = cbind(X,y[5:nrow(y)-i,])
}
 
## Pre-setup 
N             = ncol(Y)
p             = frequency(Y)
A.hat         = solve(t(X)%*%X)%*%t(X)%*%Y
Sigma.hat     = t(Y-X%*%A.hat)%*%(Y-X%*%A.hat)/nrow(Y)

# Prior distribution specification - Minnesota prior 
kappa.1       = 10                                    # shrinkage for A1 to Ap
kappa.2       = 100                                   # shrinkage for constant 
A.prior       = matrix(0,nrow(A.hat),ncol(A.hat))
A.prior[2,1]  = 1
V.prior       = diag(c(kappa.2,kappa.1*((1:p)^(-2))%x%rep(1,N)))
S.prior       = diag(diag(Sigma.hat))
nu.prior      = N+1
```

```{r forecasting basic model}
#| echo: true
#| message: false
#| warning: false
## Applying function 
posterior.sample.draws = posterior.draws(S=50000, Y=Y, X=X)
A.posterior.simu       = posterior.sample.draws$A.posterior
Sigma.posterior.simu   = posterior.sample.draws$Sigma.posterior

## Three-year ahead forecasting h=12
# set up
h                      = 12
S                      = 50000
Y.h                    = array(NA,c(h,N,S))

# sampling predictive density
for (s in 1:S){
  A.posterior.draw     = A.posterior.simu[,,s]
  Sigma.posterior.draw = Sigma.posterior.simu[,,s]
    x.Ti               = Y[(nrow(Y)-p+1):nrow(Y),]
    x.Ti               = x.Ti[p:1,]
  for (i in 1:h){
    x.T                = c(1,as.vector(t(x.Ti)))
    Y.f                = rmvnorm(1, mean = x.T%*%A.posterior.draw, sigma=Sigma.posterior.draw)
      x.Ti             = rbind(Y.f,x.Ti[1:(p-1),])
    Y.h[i,,s]          = Y.f[1:N]
  }
}

# transform cpi into annual cpi and plot
par(mfrow=c(1,1), mar=c(4,4,2,2))
point.cpi.h            = ts(round(apply(Y.h[,1,],1,mean),6))
cpi.data.h             = c(y[,1], point.cpi.h)
cpi.data.h             = rev(cpi.data.h)
annual.cpi             = matrix(NA, length(cpi.data.h)-3 , 1)
for (i in 1: (length(cpi.data.h)-3)) {
     annual.cpi[i]     = sum (cpi.data.h[i: (i+3)])
}
annual.cpi             = ts(rev(annual.cpi))
annual.cpi             = xts(annual.cpi, seq(as.Date("1992-03-01"), by = "quarter", length.out = length(annual.cpi)))

plot.ts(annual.cpi, lwd=2, col="black", xaxt='n')
axis(1,c(0,40,80,112,125, nrow(y)+h),c("1992","2002","2012","2020","2023", ""))
abline(h=0.02, col="red", lty = 2)
abline(v=125, col = "blue")
abline(v=129, col = "blue")

# cash rate plot
point.cr.h             = ts(round(apply(Y.h[,2,],1,mean),6))
cr.data.h              = c(y[,2], point.cpi.h)
qrter.cr.change        = xts(cr.data.h, seq(as.Date("1991-06-01"), by = "quarter", length.out = length(cr.data.h)))

plot.ts(qrter.cr.change, lwd=2, col="black", xaxt='n')
axis(1,c(3,43,83,115,128, nrow(y)+h),c("1992","2002","2012","2020","2023",""))
abline(h=0, col="red", lty = 2)
abline(v=128, col = "blue")
```

The $h=12$ steps ahead line plot is displayed above.

Given the inflation data used in the model is log differences, thus each data point means the quarterly inflation rate. I transformed the data by summing up the past 4 consecutive data points together for every single data point to get an annualised figure for each period. Taking a look at the plot, we can see as at 2023 Quarter 1, the annual inflation rate is over 6%; based on our forecasting, the annual inflation rate is going to gradually decrease during 2023, and reaching at the target level 2% at 2023 Quarter 4. Thereafter, the annual inflation will keep decreasing. It will turn to increase again after it reaches 0 in year 2024 to 2025.

The cash rate plot indicate the cash rate movements as compared to the prior quarter. According to the forecasts, since 2023 Quarter 1, the cash rate increased 49 basis points to $3.31\%$, it looks like that RBA will maintain the current cash rate level without increasing or decreasing the cash rate in the next 3 years, supported by the flat line at 0 as shown in above graph.

3D with density intervals for the inflation and cash rate are plotted below. Both of them illustrate the similar ideas. The quarterly inflation rate and cash rate don't seem to vary much in the next 3 years, the bounded confidence interval (i.e. green shaded area) is not wide as well. The different height of the intervals mean how certain the prediction is, as it goes further into the future, the interval become more wider and dispersed, resulting from the increased uncertainty.

```{r forecasting plot basic model}
#| echo: false
#| message: false
#| warning: false
## Forecasting plotting      
mcxs1  = "#05386B"
mcxs2  = "#379683"
mcxs3  = "#5CDB95"
mcxs4  = "#8EE4AF"
mcxs5  = "#EDF5E1"

par(mfrow=c(1,2), mar=c(2,2,1,1))
# CPI forecasting 
limits.1    = range(Y.h[,1,])
point.f     = apply(Y.h[,1,],1,mean)
interval.f  = apply(Y.h[,1,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5

x           = seq(from=limits.1[1], to=limits.1[2], length.out=100)
z           = matrix(NA,h,99)
for (i in 1:h){
  z[i,]     = hist(Y.h[i,1,], breaks=x, plot=FALSE)$density
}
x           = hist(Y.h[i,1,], breaks=x, plot=FALSE)$mids
yy          = 1:h
z           = t(z)

f4    = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1, col=NA,plot=FALSE)

perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)
polygon3D(x=c(interval.f[1,],interval.f[2,h:1]), y=c(1:h,h:1), z=rep(0,2*h), col = mcxs4, NAcol = "white", border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=0.5, col="black")
}
f4.l1 = trans3d(x=point.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=2, col=mcxs1)

# cash rate forecasting 
limits.1    = range(Y.h[,2,])
point.f     = apply(Y.h[,2,],1,mean)
interval.f  = apply(Y.h[,2,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5

x           = seq(from=limits.1[1], to=limits.1[2], length.out=100)
z           = matrix(NA,h,99)
for (i in 1:h){
  z[i,]     = hist(Y.h[i,2,], breaks=x, plot=FALSE)$density
}
x           = hist(Y.h[i,2,], breaks=x, plot=FALSE)$mids
yy          = 1:h
z           = t(z)

f4          = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab="\ncr[t+h|t]", ylab="h", zlab="\npredictive densities of cash rate", shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1, col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, xlab="\ncr[t+h|t]", ylab="h", zlab="\npredictive densities of cash rate", ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)
polygon3D(x=c(interval.f[1,],interval.f[2,h:1]), y=c(1:h,h:1), z=rep(0,2*h), col = mcxs5, NAcol = "white", border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=.5, col="black")
}
f4.l1 = trans3d(x=point.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=2,col=mcxs2)
```

### Forecasting on extended model

```{r forecasting on extended model}
#| echo: true
#| message: false
#| warning: false
## Applying function 
S1                         = 5000                              # determine the burn-in draws
S2                         = 45000                             # number of draws from the final simulation
total_S                    = S1+S2
posterior.ext              = posterior.draws.exten(total_S = total_S, Y=Y, X=X)
A.posterior.ext.simu       = posterior.ext$A.posterior.exten[,,(S1+1):total_S]
Sigma.posterior.ext.simu   = posterior.ext$Sigma.posterior.exten[,,(S1+1):total_S]

## Three-year ahead forecasting h=12
# set up
h                          = 12
S                          = 45000
Y.h.ext                    = array(NA,c(h,N,S))

# sampling predictive density
for (s in 1:S){
  A.posterior.draw         = A.posterior.ext.simu[,,s]
  Sigma.posterior.draw     = Sigma.posterior.ext.simu[,,s]
    x.Ti                   = Y[(nrow(Y)-p+1):nrow(Y),]
    x.Ti                   = x.Ti[p:1,]
  for (i in 1:h){
    x.T                    = c(1,as.vector(t(x.Ti)))
    Y.f                    = rmvnorm(1, mean = x.T%*%A.posterior.draw, sigma=Sigma.posterior.draw)
      x.Ti                 = rbind(Y.f,x.Ti[1:(p-1),])
    Y.h.ext[i,,s]          = Y.f[1:N]
  }
}

# transform cpi into annual cpi and plot
par(mfrow=c(1,1), mar=c(4,4,2,2))
point.cpi.h            = ts(round(apply(Y.h.ext[,1,],1,mean),6))
cpi.data.h             = c(y[,1], point.cpi.h)
cpi.data.h             = rev(cpi.data.h)
annual.cpi             = matrix(NA, length(cpi.data.h)-3 , 1)
for (i in 1: (length(cpi.data.h)-3)) {
     annual.cpi[i]     = sum (cpi.data.h[i: (i+3)])
}
annual.cpi             = ts(rev(annual.cpi))
annual.cpi             = xts(annual.cpi, seq(as.Date("1992-03-01"), by = "quarter", length.out = length(annual.cpi)))

plot.ts(annual.cpi, lwd=2, col="black", xaxt='n')
axis(1,c(0,40,80,112,125, nrow(y)+h),c("1992","2002","2012","2020","2023", ""))
abline(h=0.02, col="red", lty = 2)
abline(v=125, col = "blue")
abline(v=129, col = "blue")

# cash rate plot
point.cr.h             = ts(round(apply(Y.h.ext[,2,],1,mean),6))
cr.data.h              = c(y[,2], point.cpi.h)
qrter.cr.change        = xts(cr.data.h, seq(as.Date("1991-06-01"), by = "quarter", length.out = length(cr.data.h)))

plot.ts(qrter.cr.change, lwd=2, col="black", xaxt='n')
axis(1,c(3,43,83,115,128, nrow(y)+h),c("1992","2002","2012","2020","2023", ""))
abline(h=0, col="red", lty = 2)
abline(v=128, col = "blue")
```

A view of the plots above, the overall trends in the next 3 years are very similar in both basic and extended model. Only that the inflation rate would return to the target level a bit early than what's forecasted in the basic model; however there is no significant difference. The movement of cash rate is the same in both model.

The below 3D plots doesn't have many differences. Just the confidence intervals for the inflation is narrowed and every density is higher than it's in the basic model, which indicates the extended model might have a higher certainty in predicting the inflation.

```{r forecasting plot on extended model}
#| echo: false
#| message: false
#| warning: false
par(mfrow=c(1,2), mar=c(2,2,1,1))
# CPI forecasting 
limits.1    = range(Y.h.ext[,1,])
point.f     = apply(Y.h.ext[,1,],1,mean)
interval.f  = apply(Y.h.ext[,1,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5
x           = seq(from=limits.1[1], to=limits.1[2], length.out=100)
z           = matrix(NA,h,99)
for (i in 1:h){
  z[i,]     = hist(Y.h.ext[i,1,], breaks=x, plot=FALSE)$density
}
x           = hist(Y.h.ext[i,1,], breaks=x, plot=FALSE)$mids
yy          = 1:h
z           = t(z)

f4          = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", shade=NA, border=NA, ticktype ="detailed", nticks=3,cex.lab=1, col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", ticktype ="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)
polygon3D(x=c(interval.f[1,],interval.f[2,h:1]), y=c(1:h,h:1), z=rep(0,2*h), col = mcxs4, NAcol = "white", border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=0.5, col="black")
}
f4.l1 = trans3d(x=point.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=2, col=mcxs1)

# cash rate forecasting 
limits.1    = range(Y.h.ext[,2,])
point.f     = apply(Y.h.ext[,2,],1,mean)
interval.f  = apply(Y.h.ext[,2,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5

x           = seq(from=limits.1[1], to=limits.1[2], length.out=100)
z           = matrix(NA,h,99)
for (i in 1:h){
  z[i,]     = hist(Y.h.ext[i,2,], breaks=x, plot=FALSE)$density
}
x           = hist(Y.h.ext[i,2,], breaks=x, plot=FALSE)$mids
yy          = 1:h
z           = t(z)

f4          = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab="\ncr[t+h|t]", ylab="h", zlab="\npredictive densities of cash rate", shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1, col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, xlab="\ncr[t+h|t]", ylab="h", zlab="\npredictive densities of cash rate", ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)
polygon3D(x=c(interval.f[1,],interval.f[2,h:1]), y=c(1:h,h:1), z=rep(0,2*h), col = mcxs5, NAcol = "white", border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=.5, col="black")
}
f4.l1 = trans3d(x=point.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=2,col=mcxs2)
```

### Forecasting on heteroskedasticity model

```{r forecasting heteroskedasticity}
#| echo: true
#| message: false
#| warning: false
## Applying function 
S1                           = 5000                              # determine the burn-in draws
S2                           = 45000                             # number of draws from the final simulation
total_S                      = S1+S2
posterior.heter              = posterior.draw.heter(total_S = total_S, Y = Y, X = X, priors = priors)
A.posterior.heter.simu       = posterior.heter$A[,,(S1+1):total_S]
Sigma.posterior.heter.simu   = posterior.heter$Sigma[,,(S1+1):total_S]

## Three-year ahead forecasting h=12
# set up
h                            = 12
S                            = 45000
Y.h.heter                    = array(NA,c(h,N,S))

# sampling predictive density
for (s in 1:S){
  A.posterior.draw           = A.posterior.heter.simu[,,s]
  Sigma.posterior.draw       = Sigma.posterior.heter.simu[,,s]
    x.Ti                     = Y[(nrow(Y)-p+1):nrow(Y),]
    x.Ti                     = x.Ti[p:1,]
  for (i in 1:h){
    x.T                      = c(1,as.vector(t(x.Ti)))
    Y.f                      = rmvnorm(1, mean = x.T%*%A.posterior.draw, sigma=Sigma.posterior.draw)
      x.Ti                   = rbind(Y.f,x.Ti[1:(p-1),])
    Y.h.heter[i,,s]          = Y.f[1:N]
  }
}

# transform cpi into annual cpi and plot
par(mfrow=c(1,1), mar=c(4,4,2,2))
point.cpi.h            = ts(round(apply(Y.h.heter[,1,],1,mean),6))
cpi.data.h             = c(y[,1], point.cpi.h)
cpi.data.h             = rev(cpi.data.h)
annual.cpi             = matrix(NA, length(cpi.data.h)-3 , 1)
for (i in 1: (length(cpi.data.h)-3)) {
     annual.cpi[i]     = sum (cpi.data.h[i: (i+3)])
}
annual.cpi             = ts(rev(annual.cpi))
annual.cpi             = xts(annual.cpi, seq(as.Date("1992-03-01"), by = "quarter", length.out = length(annual.cpi)))

plot.ts(annual.cpi, lwd=2, col="black", xaxt='n')
axis(1,c(0,40,80,112,125, nrow(y)+h),c("1992","2002","2012","2020","2023", ""))
abline(h=0.02, col="red", lty = 2)
abline(v=125, col = "blue")
abline(v=129, col = "blue")

# cash rate plot
point.cr.h             = ts(round(apply(Y.h.heter[,2,],1,mean),6))
cr.data.h              = c(y[,2], point.cpi.h)
qrter.cr.change        = xts(cr.data.h, seq(as.Date("1991-06-01"), by = "quarter", length.out = length(cr.data.h)))

plot.ts(qrter.cr.change, lwd=2, col="black", xaxt='n')
axis(1,c(3,43,83,115,128, nrow(y)+h),c("1992","2002","2012","2020","2023", ""))
abline(h=0, col="red", lty = 2)
abline(v=128, col = "blue")
```

Like in the basic and extended model, the heteroskedasticity model gives the prediction that the annual inflation will return to the target level before the start of year 2024 as well. However, it predicts the inflation will decrease way more below 0 than the other two models, indicating the economy would experience downturn in year 2024 and 2025. This discrepancy is likely due to the time-varying volatility introduced in this model. The time dependence of the dropping inflation lasts longer and the high volatility in the inflation movements in the past period remains high in the following periods, therefore the annual inflation dropped deeper in 2024.

The forecasts on the cash rate remains consistent among three models.

3D density is plotted below for reference. It looks quite different than what we see in the basic and extended models. The densities are very sharp and concentrated around the point estimates. As we forecast further into the future, the densities do not become dispersed, whereas it preserves the similar shape as in the near periods. This may result from the varying column variance replaced each time in estimating $A$ and $\Sigma$, hence each $\Sigma$ contains more information. When forecasting into the future, it increases the certainty.

```{r forecasting plot heteroskedasticity}
#| echo: false
#| message: false
#| warning: false
par(mfrow=c(1,2), mar=c(2,2,1,1))
# CPI forecasting 
limits.1    = range(Y.h.heter[,1,])
point.f     = apply(Y.h.heter[,1,],1,mean)
interval.f  = apply(Y.h.heter[,1,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5
x           = seq(from=limits.1[1], to=limits.1[2], length.out=10)
z           = matrix(NA,h,9)
for (i in 1:h){
  z[i,]     = hist(Y.h.heter[i,1,], breaks=x, plot=FALSE)$density
}
x           = hist(Y.h.heter[i,1,], breaks=x, plot=FALSE)$mids
yy          = 1:h
z           = t(z)

f4          = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", shade=NA, border=NA, ticktype ="detailed", nticks=3,cex.lab=1, col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, xlab="\ncpi[t+h|t]", ylab="h", zlab="\npredictive densities of cpi", ticktype ="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)
polygon3D(x=c(interval.f[1,],interval.f[2,h:1]), y=c(1:h,h:1), z=rep(0,2*h), col = mcxs4, NAcol = "white", border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=0.5, col="black")
}
f4.l1 = trans3d(x=point.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=2, col=mcxs1)

# cash rate forecasting 
limits.1    = range(Y.h.heter[,2,])
point.f     = apply(Y.h.heter[,2,],1,mean)
interval.f  = apply(Y.h.heter[,2,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5

x           = seq(from=limits.1[1], to=limits.1[2], length.out=10)
z           = matrix(NA,h,9)
for (i in 1:h){
  z[i,]     = hist(Y.h.heter[i,2,], breaks=x, plot=FALSE)$density
}
x           = hist(Y.h.heter[i,2,], breaks=x, plot=FALSE)$mids
yy          = 1:h
z           = t(z)

f4          = persp3D(x=x, y=yy, z=z, phi=phi, theta=theta, xlab="\ncr[t+h|t]", ylab="h", zlab="\npredictive densities of cash rate", shade=NA, border=NA, ticktype="detailed", nticks=3,cex.lab=1, col=NA,plot=FALSE)
perspbox (x=x, y=yy, z=z, bty="f", col.axis="black", phi=phi, theta=theta, xlab="\ncr[t+h|t]", ylab="h", zlab="\npredictive densities of cash rate", ticktype="detailed", nticks=3,cex.lab=1, col = NULL, plot = TRUE)
polygon3D(x=c(interval.f[1,],interval.f[2,h:1]), y=c(1:h,h:1), z=rep(0,2*h), col = mcxs5, NAcol = "white", border = NA, add = TRUE, plot = TRUE)

for (i in 1:h){
  f4.l = trans3d(x=x, y=yy[i], z=z[,i], pmat=f4)
  lines(f4.l, lwd=.5, col="black")
}
f4.l1 = trans3d(x=point.f, y=yy, z=0, pmat=f4)
lines(f4.l1, lwd=2,col=mcxs2)
```

Interactive versions of the above 3D plots are provided below to allow access to alternative vantage points.

```{r forecasting plot basic model-plot_ly}
#| echo: false
#| message: false
#| warning: false

par(mfrow=c(1,2), mar=c(2,2,1,1))
# Log CPI forecasting 
limits.1        = range(Y.h.heter[,1,])
point.f         = apply(Y.h.heter[,1,],1,mean)
interval.f      = apply(Y.h.heter[,1,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5

x.cpi           = seq(from=limits.1[1], to=limits.1[2], length.out=10)
z.cpi           = matrix(NA,h,9)
for (i in 1:h){
  z.cpi[i,]     = hist(Y.h.heter[i,1,], breaks=x.cpi, plot=FALSE)$density
}
x.cpi           = hist(Y.h.heter[i,1,], breaks=x.cpi, plot=FALSE)$mids
yy.cpi          = 1:h

# cash rate forecasting 
limits.1    = range(Y.h.heter[,2,])
point.f     = apply(Y.h.heter[,2,],1,mean)
interval.f  = apply(Y.h.heter[,2,],1,hdi,credMass=0.90)
theta = 180
phi   = 15.5

x.cr            = seq(from=limits.1[1], to=limits.1[2], length.out=10)
z.cr            = matrix(NA,h,9)
for (i in 1:h){
  z.cr[i,]      = hist(Y.h.heter[i,2,], breaks=x.cr, plot=FALSE)$density
}
x.cr            = hist(Y.h.heter[i,2,], breaks=x.cr, plot=FALSE)$mids
yy.cr           = 1:h

# plot using plot_ly
par(mfrow=c(1,1))
plot_ly(y = yy.cpi, x = x.cpi, z=z.cpi) %>%
  
  layout(scene=list(xaxis=list(title="cpi"),
                    yaxis=list(title="h-step forecast"),
                    zaxis=list(title="density")),
         title = "CPI forecast densities") %>%
  add_surface(colors = c(mcxs1,mcxs4,mcxs5))

plot_ly(y = yy.cr, x = x.cr, z=z.cr) %>%
  
  layout(scene=list(xaxis=list(title="cash rate"),
                    yaxis=list(title="h-step forecast"),
                    zaxis=list(title="density")),
         title = "Cash rate forecast densities") %>%
  add_surface(colors = c(mcxs1,"magenta2",mcxs5))
```

## Conclusion

In this research project, we closely examined three Bayesian VARs models to forecast the variables of interest, namely the inflation $cpi_{t}$ and the cash rate $cashr_{t}$. We start from the basic model with simple Minnesota prior specifications to capture the features and dynamic relationships we found in our variables. We built a hierarchical model by imposing the Minnesota shrinkage hyperparameter kappa $k$ on top of the basic model. We enhanced the hierarchical model by introducing the stochastic volatilites. We conducted 12-step ahead forecasts on each of the models and compared the results.

The forecasts provided by the three models are similar and consistent in general with some small discrepancies. All three models provide forecasts that the annual inflation rate in three years time will be around the target level $2\%$ or less. The annual inflation in Australia will return to the annual target $2-3\%$ no later than the start of 2024. The cash rate will remain unchanged, at around $3.31\%$ as of March 2023 in the next three years.
